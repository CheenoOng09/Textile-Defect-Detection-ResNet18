# -*- coding: utf-8 -*-
"""SmartMan-1.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1KsxNHgbfq2SQmydnDzTrJyXJU1lLYXvV
"""

import numpy as np
import pandas as pd

file_path = 'drive/MyDrive/School/Smart_Man/'
#alt_file_path = '/content/sample_data2'
train = pd.read_csv(file_path + 'train32.csv')
test = pd.read_csv(file_path + 'test32.csv')
#alt_test = pd.read_csv(alt_file_path + 'alt_test.csv')
print(train)
print(test)
#print(alt_test)

from google.colab import drive
drive.mount('/content/drive')

# 0: good textile, 1: damaged textile
# Train Data
train['index'] = train['index'] - 48000
train_good = train[train['indication_value'] == 0]
train_damaged = train[train['indication_value'] != 0]
train_damaged['indication_value'] = 1

# Test Data
test['index'] = test['index']
test_good = test[test['indication_value'] == 0]
test_damaged = test[test['indication_value'] != 0]
test_damaged['indication_value'] = 1

print(test_good.count())
print(test_damaged[test['angle'] == 120].count())
print(test_damaged[test['angle'] == 20].count())

train_table = pd.concat([train_good, train_damaged[train['angle'] == 20], train_damaged[train['angle'] == 120]])
test_table = pd.concat([test_good, test_damaged[test['angle'] == 20], test_damaged[test['angle'] == 120]])

import h5py
import keras

f = h5py.File(file_path + 'train32.h5', 'r')
a_group_key = list(f.keys())[0]
data = list(f[a_group_key])

x_train = []
y_train = []
idx = train_table['index'].astype('int')
indication_value = train_table['indication_value'].astype('int')
for i in idx:
    x_train.append(data[i])
    y_train.append(indication_value.loc[idx[i]])

x_train = np.array(x_train)
y_train = np.array(y_train)
y_train = keras.utils.to_categorical(y_train, num_classes=2)

print(x_train.shape)
print(y_train.shape)

f = h5py.File(file_path + 'test32.h5', 'r')
a_group_key = list(f.keys())[0]
data = list(f[a_group_key])

x_test = []
y_test = []
idx = test_table['index'].astype('int')
indication_value = test_table['indication_value'].astype('int')
for i in idx:
    x_test.append(data[i])
    y_test.append(indication_value.loc[idx[i]])

x_test = np.array(x_test)
y_test = np.array(y_test)
y_test = keras.utils.to_categorical(y_test, num_classes=2)

print(x_test.shape)
print(y_test.shape)

# Build model
import torch
import torch.nn as nn
from torch.utils.data import Dataset, DataLoader
import torchvision.transforms as transforms
import torch.optim as optim
from torchvision.models import resnet18

device = torch.device("cuda:0" if torch.cuda.is_available() else "cpu")

# Build ResNet18 model
model = resnet18(pretrained = True)
model.conv1 = nn.Conv2d(1, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3),bias=False)

# Connect to fully connnected layer
model.fc = nn.Sequential(
    nn.Linear(512,512),
    nn.ReLU(inplace=True),
    nn.Linear(512,64),
    nn.ReLU(inplace=True),
    nn.Linear(64,2)
)

def init_weights(m):
    if isinstance(m, nn.Conv2d) or isinstance(m, nn.Linear):
        nn.init.kaiming_normal_(m.weight, mode='fan_out', nonlinearity='relu')
        if m.bias is not None:
            nn.init.constant_(m.bias, 0)

model.apply(init_weights)
model.to(device)

from sklearn.model_selection import train_test_split

# Set data loader
class cifar10Dataset(Dataset):
    def __init__(self, imgs, labels, transform=None):
        self.imgs = imgs
        self.labels = labels
        self.transforms = transform

    def __len__(self):
        return len(self.imgs)

    def __getitem__(self, index):
        x = self.imgs[index]
        y = self.labels[index]

        if self.transforms:
            x = self.transforms(x)

        x = x.float()
        return x, y

# Split train and validation
x_train, x_val, y_train, y_val = train_test_split(x_train,
                                                  y_train,
                                                  test_size=0.2,
                                                  random_state=100,
                                                  shuffle=True)

learningRate = 0.001
batch_size = 64

# Set loss function and optimiser
criterion = nn.CrossEntropyLoss()
#optimizer = optim.SGD(model.parameters(),lr = learningRate)
optimizer = optim.Adam(model.parameters(),lr = learningRate)

stats = ((0.5), (0.5))
transform = transforms.Compose([transforms.ToTensor(),
                                transforms.RandomCrop(32, padding=4, padding_mode='reflect'),
                                transforms.RandomHorizontalFlip(),
                                transforms.Normalize(*stats,inplace=True)
                               ])

train_dataset = cifar10Dataset(x_train, y_train, transform)
val_dataset = cifar10Dataset(x_val, y_val, transform)
test_dataset = cifar10Dataset(x_test, y_test, transform)
train_loader = DataLoader(dataset=train_dataset, batch_size= batch_size, shuffle=True)
val_loader = DataLoader(dataset=val_dataset, batch_size= batch_size, shuffle=True)
test_loader = DataLoader(dataset=test_dataset, batch_size= batch_size, shuffle=True)

from sklearn.model_selection import train_test_split
from torch.utils.data import Dataset, DataLoader
import torch.nn.functional as F
import torch.optim as optim
import torch.nn as nn
import torchvision.transforms as transforms

# Define Focal Loss
class FocalLoss(nn.Module):
    def __init__(self, alpha=1, gamma=2, reduction='mean'):
        super(FocalLoss, self).__init__()
        self.alpha = alpha
        self.gamma = gamma
        self.reduction = reduction

    def forward(self, inputs, targets):
        probs = F.softmax(inputs, dim=1)
        # Get the predicted probabilities for the target classes
        pt = (probs * targets).sum(dim=1)
        focal_weight = (1 - pt) ** self.gamma
        loss = -self.alpha * focal_weight * torch.log(pt + 1e-8)

        if self.reduction == 'mean':
            return loss.mean()
        elif self.reduction == 'sum':
            return loss.sum()
        else:
            return loss

# Dataset class
class cifar10Dataset(Dataset):
    def __init__(self, imgs, labels, transform=None):
        self.imgs = imgs
        self.labels = labels
        self.transforms = transform

    def __len__(self):
        return len(self.imgs)

    def __getitem__(self, index):
        x = self.imgs[index]
        y = self.labels[index]

        if self.transforms:
            x = self.transforms(x)

        x = x.float()
        return x, y

# Split train and validation
x_train, x_val, y_train, y_val = train_test_split(x_train,
                                                  y_train,
                                                  test_size=0.2,
                                                  random_state=100,
                                                  shuffle=True)

learningRate = 0.001
batch_size = 64

# Define Focal Loss and optimizer
criterion = FocalLoss(alpha=1, gamma=2)  # Use Focal Loss instead of CrossEntropyLoss
optimizer = optim.Adam(model.parameters(), lr=learningRate)

# Transformations
stats = ((0.5), (0.5))
transform = transforms.Compose([transforms.ToTensor(),
                                transforms.RandomCrop(32, padding=4, padding_mode='reflect'),
                                transforms.RandomHorizontalFlip(),
                                transforms.Normalize(*stats,inplace=True)
                               ])

# Datasets and loaders
train_dataset = cifar10Dataset(x_train, y_train, transform)
val_dataset = cifar10Dataset(x_val, y_val, transform)
test_dataset = cifar10Dataset(x_test, y_test, transform)

train_loader = DataLoader(dataset=train_dataset, batch_size=batch_size, shuffle=True)
val_loader = DataLoader(dataset=val_dataset, batch_size=batch_size, shuffle=True)
test_loader = DataLoader(dataset=test_dataset, batch_size=batch_size, shuffle=True)

from sklearn.metrics import classification_report, precision_score, recall_score, f1_score

# Training loop
num_epoch = 20
best_val_accuracy = 0.0

for epoch in range(num_epoch):
    model.train()
    for images, labels in train_loader:
        images, labels = images.to(device), labels.to(device)
        optimizer.zero_grad()
        outputs = model(images)
        loss = criterion(outputs, labels)  # Using Focal Loss
        loss.backward()
        optimizer.step()

    model.eval()
    all_labels = []
    all_predictions = []
    with torch.no_grad():
        correct = 0
        total = 0
        for images, labels in val_loader:
            images, labels = images.to(device), labels.to(device)
            outputs = model(images)
            _, predicted = torch.max(outputs.data, 1)  # Predictions

            # Get the target class indices from one-hot encoded labels
            _, true_labels = torch.max(labels, 1) # changed to get the index of true label

            all_labels.extend(true_labels.cpu().numpy())
            all_predictions.extend(predicted.cpu().numpy())

            total += true_labels.size(0)
            correct += (predicted == true_labels).sum().item()

        # Calculate validation accuracy
        val_accuracy = correct / total

        # Save the best model based on validation accuracy
        if val_accuracy > best_val_accuracy:
            best_val_accuracy = val_accuracy
            torch.save(model.state_dict(), file_path + 'best_model_adam_cross.pth')

        # Compute precision, recall, and F1 score
        precision = precision_score(all_labels, all_predictions, average='weighted')
        recall = recall_score(all_labels, all_predictions, average='weighted')
        f1 = f1_score(all_labels, all_predictions, average='weighted')

        # Print metrics for the epoch
        print(f'Epoch [{epoch+1}/{num_epoch}], '
              f'Validation Accuracy: {val_accuracy:.4f}, '
              f'BEST Accuracy: {best_val_accuracy:.4f}, '
              f'Precision: {precision:.4f}, '
              f'Recall: {recall:.4f}, '
              f'F1 Score: {f1:.4f}')

print('Training Finished!')

import matplotlib.pyplot as plt
from sklearn.metrics import precision_score, recall_score, f1_score, classification_report

# Load the model
model.load_state_dict(torch.load(file_path + 'best_model_sgd_cross.pth'))
model.eval()

total = 0
correct = 0
all_labels = []
all_predictions = []

# Evaluate the model
for images, labels in test_loader:
    images, labels = images.to(device), labels.to(device)
    batch_outputs = model(images)
    _, predicted = torch.max(batch_outputs, 1)
    _, true_labels = torch.max(labels, 1)  # Only needed if labels are one-hot encoded

    total += true_labels.size(0)
    correct += (predicted == true_labels).sum().item()

    # Collect predictions and true labels for metrics
    all_labels.extend(true_labels.cpu().numpy())
    all_predictions.extend(predicted.cpu().numpy())

# Calculate accuracy
test_accuracy = correct / total

# Calculate precision, recall, and F1 score
precision = precision_score(all_labels, all_predictions, average='weighted')
recall = recall_score(all_labels, all_predictions, average='weighted')
f1 = f1_score(all_labels, all_predictions, average='weighted')

# Print results
print(f'Test Accuracy: {test_accuracy:.4f}')
print(f'Precision: {precision:.4f}')
print(f'Recall: {recall:.4f}')
print(f'F1 Score: {f1:.4f}')
print('\nClassification Report:\n', classification_report(all_labels, all_predictions))

# Prepare data for the bar graph
metrics = ['Accuracy', 'Precision', 'Recall', 'F1 Score']
values = [test_accuracy, precision, recall, f1]

# Plot bar graph
plt.figure(figsize=(8, 6))
plt.bar(metrics, values, color=['blue', 'orange', 'green', 'red'])
plt.ylim(0, 1)  # Scores are between 0 and 1
plt.title('Model Performance Metrics')
plt.ylabel('Score')
plt.xlabel('Metrics')
plt.grid(axis='y', linestyle='--', alpha=0.7)
plt.show()

import torch
import torchvision.transforms as transforms
from PIL import Image
import os

# Set device
device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')

# Function to preprocess a single image
def preprocess_image(image_path, model):
    image = Image.open(image_path)  # Open image

    # Check the number of input channels for the first convolutional layer
    input_channels = model.conv1.in_channels

    if input_channels == 3:  # Model expects RGB
        image = image.convert('RGB')
    elif input_channels == 1:  # Model expects Grayscale
        image = image.convert('L')
    else:
        raise ValueError(f"Unexpected input channels: {input_channels}")

    transform = transforms.Compose([
        transforms.Resize((32, 32)),  # Resize to match model input
        transforms.ToTensor(),
        transforms.Normalize(mean=[0.5] * input_channels, std=[0.5] * input_channels)  # Update normalization
    ])
    image = transform(image)
    image = image.unsqueeze(0)  # Add batch dimension
    return image

# Directory containing the images
image_directory = 'drive/MyDrive/School/Smart_Man/Test_Images'

# Loop through the images in the directory
for filename in os.listdir(image_directory):
    if filename.lower().endswith(('.png', '.jpg', '.jpeg')):  # Check for image file extensions
        image_path = os.path.join(image_directory, filename)
        try:
            input_image = preprocess_image(image_path, model)
            input_image = input_image.to(device)

            with torch.no_grad():
                outputs = model(input_image)
                _, predicted = torch.max(outputs, 1)  # Get predicted class

            print(f"Image: {filename}, Predicted class: {predicted.item()}")
        except Exception as e:
            print(f"Error processing image {filename}: {e}")